# CloudScaler

**CloudScaler** is a Kubernetes operator that automatically scales down and/or up any Kubernetes workloads (deployment, statefulset, cronjob) based on custom schedules. By optimizing resource scaling, CloudScaler helps reduce cloud infrastructure costs while maintaining application performance.

## Features

- **Scheduled Scaling**: Define time-based schedules to scale down deployments outside of regular operating hours, such as nights or weekends.
- **Automatic Resource Optimization**: Dynamically adjusts replicas for targeted Deployments and StatefulSets according to custom schedules or usage metrics.
- **Flexible Configuration**: Allows fine-grained control of scaling rules per application or namespace, supporting diverse workloads and policies.
- **Cost Efficiency**: Optimizes cloud spending by reducing resources during off-peak hours without impacting application availability.
- **Built-in Observability**: Offers logs and metrics for monitoring scaling activities, helping to track cost savings and understand resource usage.

## How It Works

CloudScaler operates by watching for Deployments and StatefulSets in a specified namespace (or across multiple namespaces). It reads scaling rules from a ConfigMap or CRD (Custom Resource Definition), then adjusts replicas based on defined schedules or usage thresholds.

## Requirements

- Kubernetes cluster version 1.18+
- Go 1.16+ if building from source
- Permissions to deploy custom Kubernetes operators

## Installation

### Using Helm

1. Add the CloudScaler Helm repository:
   ```bash
   helm repo add cloudscaler https://your-repo-url.com/cloudscaler
   ```

2. Install CloudScaler in your Kubernetes cluster:
   ```bash
   helm install cloudscaler cloudscaler/cloudscaler-operator
   ```

### Manual Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/cloudscaler.git
   cd cloudscaler
   ```

2. Deploy CloudScaler using kubectl:
   ```bash
   kubectl apply -f deploy/cloudscaler-operator.yaml
   ```

## Usage

1. Define scaling rules using a ConfigMap or Custom Resource (CRD). Example rule:

   ```yaml
   apiVersion: cloudscaler.io/v1alpha1
   kind: ScalingRule
   metadata:
     name: my-app-scaling-rule
   spec:
     target:
       namespace: "production"
       deploymentName: "my-app"
     schedule:
       scaleDown: 1
       scaleUp: 5
       activeHours:
         start: "08:00"
         end: "18:00"
   ```

   This example scales `my-app` to 1 replica outside of the `08:00` - `18:00` window and up to 5 replicas during active hours.

2. Apply the scaling rule to your cluster:
   ```bash
   kubectl apply -f config/scaling-rule.yaml
   ```

## Configuration Options

CloudScaler supports several configuration options for each scaling rule:

- **namespace**: The namespace of the target deployment or StatefulSet
- **deploymentName** or **statefulSetName**: The name of the Kubernetes resource to scale
- **scaleDown**: The number of replicas to reduce to during off-hours
- **scaleUp**: The number of replicas to maintain during active hours
- **activeHours**: Time range for scaling up

## Observability and Monitoring

CloudScaler provides logs and metrics for monitoring scaling actions and resource adjustments. Metrics are available at a `/metrics` endpoint, compatible with Prometheus for cluster-wide observability.

## Roadmap

- Enhanced metric-based scaling using Kubernetes Metrics API
- Improved CLI for rule management
- UI for configuring and monitoring scaling activities

## Contributing

Contributions are welcome! Please report bugs and feature requests by opening an issue, or submit a pull request to help improve CloudScaler.

## License

This project is licensed under the Apache License 2.0. See the [LICENSE](LICENSE) file for more details.
